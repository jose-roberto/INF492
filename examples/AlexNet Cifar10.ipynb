{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPu1wXgAtmvk"
   },
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyE_c8nhuS3n"
   },
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bx0bx2xZ4IqN",
    "outputId": "7418b577-57eb-44e3-ab18-7a2bd133a48d"
   },
   "outputs": [],
   "source": [
    "datasets_path     = '/homeLocal/michelms/praticas-cv-cnn/datasets/'\n",
    "models_path       = '/homeLocal/michelms/praticas-cv-cnn/models/'\n",
    "tensorboard_path  = '/homeLocal/michelms/praticas-cv-cnn/Tensorboard/alexnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORSd_DtSt7or"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBfb6tHXuG3y"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def my_imshow(img, dataset):\n",
    "  \n",
    "    if dataset == 'cifar10' :    \n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "    \n",
    "    img = torchvision.utils.make_grid(img[:10],nrow=5)\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    npimg = np.transpose(npimg, (1, 2, 0))  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(npimg, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "def show_images(train_loader, test_loader, dataset) :\n",
    "    print('Train samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images, dataset)\n",
    "\n",
    "    print('Test samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(test_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images, dataset)\n",
    "\n",
    "def get_data_cifar10 ( batch_size, dataset, show_image=False ) :\n",
    "  \n",
    "    my_transform_test = torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.Resize(227),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Normalize(\n",
    "                                    mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "                                    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "                        root=f'{datasets_path}/train/', \n",
    "                        train=True, \n",
    "                        transform=torchvision.transforms.ToTensor(),\n",
    "                        download=False\n",
    "                                )\n",
    "    test_dataset  = torchvision.datasets.CIFAR10(\n",
    "                        root=f'{datasets_path}/test/',\n",
    "                        train=False, \n",
    "                        transform=my_transform_test, \n",
    "                        download=False\n",
    "                                )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False\n",
    "                                )\n",
    "    test_loader  = DataLoader(test_dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False\n",
    "                                )\n",
    "\n",
    "    if show_image :\n",
    "        show_images(train_loader, test_loader, dataset)\n",
    "    \n",
    "    return train_loader, test_loader, len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "wjs7z421v726",
    "outputId": "c921f7d7-d80c-47d8-f9a3-8a77ee2a2158"
   },
   "outputs": [],
   "source": [
    "_ = get_data_cifar10(batch_size=256, dataset='cifar10', show_image=True)\n",
    "del _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUZVS7myuD7Z"
   },
   "source": [
    "# Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRZy3mjSuS4y"
   },
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8yJxo8_LKQg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlexNet(nn.Module) :\n",
    "  \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11,11), padding=0, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5,5), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, debug=False):\n",
    "        if debug : print('input',x.shape)\n",
    "        y = self.extractor(x)\n",
    "        if debug : print('extractor',y.shape)\n",
    "        y = self.flatten(y)\n",
    "        if debug : print('flatten',y.shape)\n",
    "        y = self.classifier(y)\n",
    "        if debug : print('classifier',y.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjE_rDZOmfd6"
   },
   "source": [
    "## Informações sobre a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSgF-6wD7__",
    "outputId": "68a091b0-aef5-47ce-c11b-81be0459d093"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on CUDA.\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "\n",
    "net = AlexNet( num_classes=10 )\n",
    "net = net.to(my_device)\n",
    "\n",
    "a = torch.rand( (1, 3, 227, 227) )\n",
    "a = a.to(my_device)\n",
    "\n",
    "b = net( a , debug=True )\n",
    "\n",
    "del a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_TfzVGVRrsL",
    "outputId": "2be58255-a4dd-4337-c257-3229b07adf5b"
   },
   "outputs": [],
   "source": [
    "summary(net, input_size=(3,227,227), batch_size=2000, device=my_device.type)\n",
    "del net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b13rYc5AuT1J"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMTNH0AbhSfo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import kornia.augmentation as K\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_layers ( net , writer, epoch ) :\n",
    "    layers = list(net.extractor.modules())\n",
    "    \n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Conv2d) :\n",
    "\n",
    "            writer.add_histogram(f'Bias/conv{layer_id}', layer.bias, \n",
    "                                epoch )\n",
    "            writer.add_histogram(f'Weight/conv{layer_id}', layer.weight, \n",
    "                                epoch )\n",
    "            writer.add_histogram(f'Grad/conv{layer_id}', layer.weight.grad, \n",
    "                                    epoch )\n",
    "            layer_id += 1\n",
    "\n",
    "\n",
    "def train ( dataset, prefix=None, upper_bound=100.0, save=False, epochs=100, \n",
    "           lr=1e-1, device='cpu', debug=False, layers2tensorboard=True , batch_size=64) :\n",
    "\n",
    "    if dataset == 'cifar10' :\n",
    "        cifar_data = get_data_cifar10(batch_size, \n",
    "                                    dataset, \n",
    "                                    show_image=True\n",
    "                                    )\n",
    "        train_loader, test_loader, dataset_size = cifar_data\n",
    "        num_classes = 10\n",
    "    else :\n",
    "        print('Error, dataloader is not implemented.')\n",
    "        return None\n",
    "\n",
    "    net = AlexNet( num_classes )\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    now = datetime.now()\n",
    "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = suffix if prefix is None else prefix + '-' + suffix  \n",
    "\n",
    "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
    "        \n",
    "    accuracies = []\n",
    "    max_accuracy = -1.0  \n",
    "    \n",
    "    # Define augmentation transformations\n",
    "    transform_train = nn.Sequential(\n",
    "        K.RandomHorizontalFlip(p=0.5),\n",
    "        K.RandomVerticalFlip(p=0.5),\n",
    "        K.RandomRotation(degrees=15.0, p=0.5),\n",
    "        K.RandomCrop(size=(227, 227), p=0.5),  \n",
    "        K.ColorJitter(brightness=0.2, contrast=0.2, p=0.5),\n",
    "        K.Resize(227),  \n",
    "        K.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "    )\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Training epochs...') :\n",
    "        net.train()\n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "            # print(type(train_x))\n",
    "            # print(train_x.shape)\n",
    "            \n",
    "            train_x = transform_train(train_x)  # Augment the full batch\n",
    "\n",
    "            # print(type(train_x))\n",
    "            # print(train_x.shape)\n",
    "\n",
    "            # my_imshow(train_x , 'cifar10')\n",
    "            \n",
    "            train_x = train_x.to(device)\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            predict_y = net( train_x )\n",
    "            \n",
    "            # Loss:\n",
    "            error = criterion( predict_y , train_label )\n",
    "\n",
    "            writer.add_scalar( 'Loss/train', error.cpu().item(), \n",
    "                                idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            # Back propagation\n",
    "            optimizer.zero_grad()\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accuracy:\n",
    "            predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "            correct    = torch.sum(predict_ys == train_label)\n",
    "\n",
    "            writer.add_scalar( 'Accuracy/train', correct/train_x.size(0), \n",
    "                                idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            if debug and idx % 10 == 0 :\n",
    "                print( f'idx: {idx:4d}, _error: {error.cpu().item():5.2f}' )\n",
    "\n",
    "        if layers2tensorboard :\n",
    "            plot_layers( net, writer, epoch )\n",
    "\n",
    "        accuracy = validate(net, test_loader, device=device)\n",
    "        accuracies.append(accuracy)\n",
    "        writer.add_scalar( 'Accuracy/test', accuracy, epoch )\n",
    "        \n",
    "        if accuracy > max_accuracy :\n",
    "            best_model = copy.deepcopy(net)\n",
    "            max_accuracy = accuracy\n",
    "            print(\"Saving Best Model with Accuracy: \", accuracy)\n",
    "        \n",
    "        print( f'Epoch: {epoch+1:3d} | Accuracy : {accuracy:7.4f}%' )\n",
    "\n",
    "        if accuracy > upper_bound :\n",
    "            break\n",
    "    \n",
    "    if save : \n",
    "        path = f'{models_path}AlexNet-{dataset}-{max_accuracy:.2f}.pkl'\n",
    "        torch.save(best_model, path)\n",
    "        print('Model saved in:',path)\n",
    "    \n",
    "    plt.plot(accuracies)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return best_model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29b7GjCEx9Az"
   },
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjKYp5S_x-mZ"
   },
   "outputs": [],
   "source": [
    "def validate ( model , data , device='cpu') :\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    sum = 0\n",
    "    \n",
    "    for idx, (test_x, test_label) in enumerate(data) : \n",
    "        test_x = test_x.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "        predict_y = model( test_x ).detach()\n",
    "        predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "        sum = sum + test_x.size(0)\n",
    "        correct = correct + torch.sum(predict_ys == test_label)\n",
    "        correct = correct.cpu().item()\n",
    "    \n",
    "    return correct*100./sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCON1Nm1MYIk"
   },
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXQZ0SWhPuxF"
   },
   "source": [
    "## Treina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "u_naT_XMdkys",
    "outputId": "ef1c46a7-084d-4f1a-f434-7f0ded8d2b9d"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "    print(\"CUDA Available.\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "\n",
    "print(f'Running on {my_device.type}')\n",
    "    \n",
    "dataset = 'cifar10' # 'mnist' ou 'cifar10'\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "prefix = f'AlexNet-{dataset}-e-{epochs}-lr-{lr}'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "net = train(dataset=dataset, epochs=epochs, device=my_device, save=True, \n",
    "            prefix=prefix, lr=lr, layers2tensorboard=True, batch_size=3076)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDyTFEv9zyHw"
   },
   "source": [
    "# Carregar dado e inferir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUWk9yPdz0dO"
   },
   "outputs": [],
   "source": [
    "def sample_and_predict ( dataset='cifar10', seed=None ) :\n",
    "\n",
    "    if seed is not None :\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    i = np.random.randint(10000)\n",
    "    \n",
    "    if dataset == 'cifar10' :\n",
    "        my_transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.Resize(227),\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize(\n",
    "                                mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "                                    ])\n",
    "        data  = torchvision.datasets.CIFAR10(\n",
    "                        root=f'{datasets_path}/test/',\n",
    "                        train=False, \n",
    "                        download=False\n",
    "                                )\n",
    "        sample = data[i][0]\n",
    "        plt.figure(figsize=(2,2))\n",
    "        plt.axis('off')\n",
    "        plt.imshow( sample )\n",
    "\n",
    "    else :\n",
    "        print('ERROR: Dataset not defined.')\n",
    "        return False\n",
    "\n",
    "\n",
    "    print( f'Sample id: {i:3d}' )\n",
    "    \n",
    "    x = my_transform(sample)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = x.unsqueeze_(0)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = x.to(my_device)\n",
    "    \n",
    "    output = net ( x )\n",
    "    softmax = nn.functional.softmax(output, dim=-1)\n",
    "    y = torch.max(softmax, 1)[1]\n",
    "    confidence = torch.max(softmax, 1)[0]\n",
    "    y = y.data.cpu().item()\n",
    "    confidence = confidence.data.cpu().item()\n",
    "    \n",
    "    if dataset == 'cifar10' :\n",
    "        dataset_classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "        if y == data[i][1] : print('Hit')\n",
    "        else: print('Miss')\n",
    "\n",
    "        print( f'Predicted: {dataset_classes[y]} | Corrected: {dataset_classes[data[i][1]]} | Confidence: {confidence*100:.2f}%'  )\n",
    "        \n",
    "        return dataset_classes[y], dataset_classes[data[i][1]], confidence\n",
    "\n",
    "    return y, data[i][1], confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sample_and_predict()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "practice-4-AlexNet_pytorch-inf492-cvcnn-2021",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
