{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLJFdPLELJ3-"
   },
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51949,
     "status": "ok",
     "timestamp": 1717759140514,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "lE7w5DYUk9zq",
    "outputId": "aa5e600e-783d-4482-922e-afe4d9830a09"
   },
   "outputs": [],
   "source": [
    "dataset_path      = ''\n",
    "models_path       = ''\n",
    "tensorboard_path  = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX3Yq3N2kp7K"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6055,
     "status": "ok",
     "timestamp": 1717759202782,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "C3o3iRb0ksSu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def my_imshow(img, fig_size=0):\n",
    "\n",
    "    img = torchvision.utils.make_grid(img[:10],nrow=5)\n",
    "\n",
    "    npimg = img.numpy()\n",
    "\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    npimg = np.clip(npimg, 0, 1)  # Clips values to the valid range\n",
    "\n",
    "    if fig_size != 0:\n",
    "        plt.figure(figsize=(fig_size, fig_size))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(npimg, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "def show_images(train_loader, test_loader) :\n",
    "    print('Train samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images)\n",
    "\n",
    "    print('Test samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(test_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images)\n",
    "\n",
    "def get_data_mnist ( batch_size, show_image=False , seed=None) :\n",
    "\n",
    "    my_transform = torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.Resize(32),\n",
    "                                    torchvision.transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.mnist.MNIST(\n",
    "                                root=f'{dataset_path}/train/',\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=my_transform\n",
    "                                )\n",
    "    test_dataset  = torchvision.datasets.mnist.MNIST(\n",
    "                                root=f'{dataset_path}/test/',\n",
    "                                train=False,\n",
    "                                download=False,\n",
    "                                transform=my_transform\n",
    "                                )\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True\n",
    "                                )\n",
    "    test_loader  = DataLoader(test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False\n",
    "                                )\n",
    "\n",
    "    if show_image :\n",
    "        show_images(train_loader, test_loader)\n",
    "\n",
    "    return train_loader, test_loader, len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCZ_gUJYha58"
   },
   "source": [
    "# Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFUIw-KSuP_x"
   },
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717760513403,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "BV4FRd59gKI_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AE(nn.Module) :\n",
    "\n",
    "  def __init__(self, in_channels=3, encoded_space_dim=100):\n",
    "    super(self.__class__, self).__init__()\n",
    "\n",
    "    dim1 = 16\n",
    "    dim2 = 32\n",
    "    dim3 = 64\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=dim1, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=dim1, out_channels=dim2, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=dim2, out_channels=dim3, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "    self.encoder_lin = nn.Sequential(\n",
    "        nn.Linear(4 * 4 * dim3, encoded_space_dim),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.decoder_lin = nn.Sequential(\n",
    "        nn.Linear(encoded_space_dim, 4 * 4 * dim3),\n",
    "        nn.ReLU(True)\n",
    "    )\n",
    "\n",
    "    self.unflatten = nn.Unflatten(dim=1, unflattened_size=(dim3, 4, 4))\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=dim3, out_channels=dim2, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels=dim2, out_channels=dim1, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels=dim1, out_channels=in_channels, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "  def forward(self, x, debug=False):\n",
    "    if debug : print('input',x.shape)\n",
    "    y = self.encoder(x)\n",
    "    if debug : print('enconder',y.shape)\n",
    "    y = self.flatten(y)\n",
    "    if debug : print('flatten',y.shape)\n",
    "    y = self.encoder_lin(y)\n",
    "    if debug : print('enconder linear',y.shape)\n",
    "    y = self.decoder_lin(y)\n",
    "    if debug : print('deconder linear',y.shape)\n",
    "    y = self.unflatten(y)\n",
    "    if debug : print('unflatten',y.shape)\n",
    "    y = self.decoder(y)\n",
    "    if debug : print('decoder',y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-n_ih_kP_rt"
   },
   "source": [
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1717760639974,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "3_Baol2jQCLx"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) :\n",
    "        # Weights:\n",
    "        # nn.init.constant_(m.weight.data, 0)\n",
    "        # nn.init.constant_(m.weight.data, 1)\n",
    "        # torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        # torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        # torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "        # Bias:\n",
    "        # nn.init.constant_(m.bias.data, 0)\n",
    "        if m.bias is not None:\n",
    "            fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            bound = 1 / math.sqrt(fan_out)\n",
    "            nn.init.normal_(m.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMuuVSTLlGcg"
   },
   "source": [
    "## Informações sobre a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1717760645423,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "tM4AtSz9lNgy",
    "outputId": "279d7a32-7efa-40b5-c47a-40018ef0b268"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on {my_device.type}\")\n",
    "\n",
    "in_channel = 1\n",
    "net = AE( in_channel, encoded_space_dim=100 )\n",
    "\n",
    "net = net.to(my_device)\n",
    "\n",
    "test_tensor = torch.rand( (1, in_channel, 32, 32) )\n",
    "test_tensor = test_tensor.to(my_device)\n",
    "test_output = net( test_tensor , debug=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1717760684068,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "lSNAaLoTlJWP",
    "outputId": "66b640cb-88f0-4d2d-c0bc-fe0e9a4bd6c7"
   },
   "outputs": [],
   "source": [
    "summary(net, input_size=(in_channel,32,32), batch_size=32)\n",
    "del test_output, test_tensor, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9myZba3ujdw"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717760724685,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "ndSU_1AUOM5c"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=.4):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1717762567169,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "2Qv5m8FsupCZ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "def train ( batch_size, lr, epochs, prefix=None, device='cpu', debug=False, dim=100) :\n",
    "\n",
    "    train_loader, test_loader, dataset_size = get_data_mnist(batch_size, show_image=True)\n",
    "    in_channels = 1\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    net = AE ( in_channels=in_channels , encoded_space_dim=dim)\n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    now = datetime.now()\n",
    "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = suffix if prefix is None else prefix + '-' + suffix\n",
    "\n",
    "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
    "\n",
    "    losses = []\n",
    "    smaller_loss = 1000.0\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "\n",
    "    for epoch in range(epochs) :\n",
    "        net.train()\n",
    "        for idx, (train_x, _ ) in enumerate(train_loader):\n",
    "            train_noise_x = add_noise(train_x)\n",
    "            train_noise_x = train_noise_x.to(device)\n",
    "            train_x = train_x.to(device)\n",
    "\n",
    "            predict_y = net( train_noise_x )\n",
    "            \n",
    "            # Loss:\n",
    "            error = criterion( predict_y , train_x )\n",
    "\n",
    "            writer.add_scalar( 'Loss/train', error.item(), idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            # Back propagation\n",
    "            optimizer.zero_grad()\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if debug and idx % 10 == 0 :\n",
    "                print( 'idx: {}, _error: {}'.format( idx, error.item() ) )\n",
    "\n",
    "        loss_test = validate(net, test_loader, writer, epoch, device=device)\n",
    "        losses.append(loss_test)\n",
    "        writer.add_scalar( 'Loss/test', loss_test, epoch )\n",
    "\n",
    "        if loss_test < smaller_loss :\n",
    "            best_model = copy.deepcopy(net)\n",
    "            smaller_loss = loss_test\n",
    "            print(f\"Saving Best Model with Loss: {loss_test:2.2f}\" )\n",
    "\n",
    "        print( 'Epoch: {:3d} | Loss : {:3.4f}'.format(epoch+1, loss_test) )\n",
    "\n",
    "    plt.plot(losses)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hr1UXKPLVRN"
   },
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1717762654485,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "-dISljT2LX81"
   },
   "outputs": [],
   "source": [
    "def validate ( model , data, writer, step, device='cpu') :\n",
    "\n",
    "    model.eval()\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    total_error = 0\n",
    "    num_images = 12\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "\n",
    "    for idx, (test_x, _) in enumerate(data) :\n",
    "        \n",
    "        test_noise_x = add_noise(test_x)\n",
    "\n",
    "        test_noise_x = test_noise_x.to(device)\n",
    "        test_x = test_x.to(device)\n",
    "\n",
    "        with torch.no_grad() :\n",
    "            predict_y = model( test_noise_x ).detach()\n",
    "\n",
    "        error = criterion( predict_y , test_x )\n",
    "        total_error = total_error + error.item()\n",
    "\n",
    "        if idx == 1 :\n",
    "            img_noise =  torchvision.utils.make_grid(test_noise_x[:num_images], nrow=num_images//2)\n",
    "            writer.add_image(\"Noise input\", img_noise, global_step=step)\n",
    "\n",
    "            img_target =  torchvision.utils.make_grid(test_x[:num_images], nrow=num_images//2)\n",
    "            writer.add_image(\"Target\", img_target, global_step=step)\n",
    "\n",
    "            img_reconstructed = torchvision.utils.make_grid(predict_y[:num_images],nrow=num_images//2)\n",
    "            writer.add_image(\"Reconstructed\", img_reconstructed, global_step=step)\n",
    "\n",
    "    return total_error/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TivQVyJcRhH8"
   },
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbwh-avcxvub"
   },
   "source": [
    "## Treina MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 307338,
     "status": "ok",
     "timestamp": 1717762977242,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "8_LUQxfQx685",
    "outputId": "60bdcd8f-23bd-4d95-d893-04623fcbacc6"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on {my_device.type}\")\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 2000\n",
    "prefix = 'AE-mnist'\n",
    "lr=1e-4\n",
    "\n",
    "net_mnist = train(batch_size=batch_size, epochs=epochs, device=my_device, lr=lr, prefix=prefix, dim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7kFaEx5c1Ia"
   },
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717763130202,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "qoSoKi_zXOg8"
   },
   "outputs": [],
   "source": [
    "def test_image_reconstruction(net, device, num_images=10):\n",
    "\n",
    "    test_loader = get_data_mnist(batch_size=32)[1]\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "\n",
    "    img = next(iter(test_loader))[0]\n",
    "\n",
    "    img_noise = add_noise(img)\n",
    "    img_noise = img_noise.to(device)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = net( img_noise )\n",
    "\n",
    "    print(\"Original:\")\n",
    "    my_imshow(torchvision.utils.make_grid(img[:num_images], nrow=num_images//2).cpu())\n",
    "\n",
    "    print(\"Noise:\")\n",
    "    my_imshow(torchvision.utils.make_grid(img_noise[:num_images], nrow=num_images//2).cpu())\n",
    "\n",
    "    print(\"Reconstructed:\")\n",
    "    my_imshow(torchvision.utils.make_grid(outputs[:num_images], nrow=num_images//2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1717763143147,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "z_0DyzO3YbxM",
    "outputId": "f307109f-4821-47be-b1e1-c1b915c8f213"
   },
   "outputs": [],
   "source": [
    "test_image_reconstruction(net_mnist, my_device, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XWTh4jlc6eY"
   },
   "outputs": [],
   "source": [
    "def sample_and_predict ( net, my_device='cpu', seed=None ) :\n",
    "\n",
    "    if seed is not None :\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    my_transform = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.Resize(32),\n",
    "                        torchvision.transforms.ToTensor()\n",
    "                                ])\n",
    "    data = torchvision.datasets.MNIST(\n",
    "                        root=f'{dataset_path}/test/',\n",
    "                        train=False,\n",
    "                        download=False\n",
    "                            )\n",
    "\n",
    "    i = np.random.randint(len(data))\n",
    "    sample = data[i][0]    \n",
    "\n",
    "    x = my_transform(sample)\n",
    "    \n",
    "    print('Original:')\n",
    "    my_imshow(x, fig_size=2)\n",
    "    \n",
    "    x = x.unsqueeze_(0)\n",
    "    \n",
    "    add_noise = AddGaussianNoise()\n",
    "    x = add_noise(x)\n",
    "\n",
    "    print('Noise:')\n",
    "    my_imshow(x, fig_size=2)\n",
    "\n",
    "    x = x.to(my_device)\n",
    "\n",
    "    output = net ( x )\n",
    "\n",
    "    print('Output:')\n",
    "    my_imshow(output.cpu(), fig_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1717683693761,
     "user": {
      "displayName": "Michel Melo da Silva",
      "userId": "16546242079425504309"
     },
     "user_tz": 180
    },
    "id": "0-019896dlmD",
    "outputId": "e612a082-513f-452d-9259-76f91c0f8881"
   },
   "outputs": [],
   "source": [
    "sample_and_predict(net_mnist, my_device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9k5dIAIPFWH7b4OXhuZkB",
   "provenance": [
    {
     "file_id": "1OkW2zTR671td_436rW308qyilrjJDs_d",
     "timestamp": 1630933321614
    },
    {
     "file_id": "12AkhoaRO4tj_sv3hqqZ549sckKh8hLsZ",
     "timestamp": 1630929936616
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
